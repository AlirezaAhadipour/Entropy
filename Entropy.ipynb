{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOh3E9nrSO/pE7YgbxgeCac",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlirezaAhadipour/Entropy/blob/main/Entropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropy"
      ],
      "metadata": {
        "id": "SRRPKfKakKGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approximate Entropy (ApEn)"
      ],
      "metadata": {
        "id": "lGBaDZkt_YSq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YALfGuY_Vcr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def approx_entropy(U, m, r):\n",
        "    N = len(U)\n",
        "\n",
        "    def max_dist(x_i, x_j):\n",
        "        return max(abs(x - y) for x, y in zip(x_i, x_j))\n",
        "\n",
        "    def phi(m):\n",
        "        n = N - m + 1\n",
        "        x = [[U[j] for j in range(i, i + m - 1 + 1)] for i in range(n)]\n",
        "        C = [len([1 for x_j in x if max_dist(x_i, x_j) <= r]) / n for x_i in x]\n",
        "\n",
        "        return sum(np.log(C)) / n\n",
        "\n",
        "    return abs(phi(m + 1) - phi(m))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "U = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]   # deterministic\n",
        "m = 2\n",
        "r = 0.2\n",
        "\n",
        "approx_entropy(U, m, r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN4cfWKnBIW0",
        "outputId": "e4020df3-88c3-49cc-ffd7-cb6418f0f1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.006185603962621911"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "U = np.random.randint(2, size=10)  # random\n",
        "m = 2\n",
        "r = 0.2\n",
        "\n",
        "approx_entropy(U, m, r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20zpO-a9Czro",
        "outputId": "8f1dc088-934f-46c1-b01f-9a8ac5793ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39126737094036934"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMatyGCRAEfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Entropy (SampEn)"
      ],
      "metadata": {
        "id": "fqHmMhFGUDuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sample_entropy(U, m, r):\n",
        "    N = len(U)\n",
        "\n",
        "    def max_dist(x_i, x_j):\n",
        "        return max(abs(x - y) for x, y in zip(x_i, x_j))\n",
        "\n",
        "    def phi(m):\n",
        "        n = N - m + 1\n",
        "        x = [[U[j] for j in range(i, i + m)] for i in range(n)]\n",
        "        C = [len([1 for x_j in x if max_dist(x_i, x_j) <= r]) for x_i in x]\n",
        "\n",
        "        return sum(C) / (n * (n - 1))\n",
        "\n",
        "    return -np.log(phi(m + 1) / phi(m))"
      ],
      "metadata": {
        "id": "qKEfqQF3UIqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0]   # deterministic\n",
        "m = 2\n",
        "r = 0.2\n",
        "\n",
        "sample_entropy(U, m, r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdEQcJjIXyd7",
        "outputId": "6656787a-78f6-4824-aa09-7fde34bb7554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0034782643763247925"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "U = np.random.randint(2, size=10)  # random\n",
        "m = 2\n",
        "r = 0.2\n",
        "\n",
        "sample_entropy(U, m, r)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGow0qZqXyIP",
        "outputId": "0993b967-2e7e-46e8-d386-0491597c9d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24512245803298496"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c7cn2cZCtt2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Permutation Entropy (PE)"
      ],
      "metadata": {
        "id": "XcN821BZAGEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import math\n",
        "\n",
        "def permutation_entropy(time_series, m, delay):\n",
        "    n = len(time_series)\n",
        "\n",
        "    # Create a list of all possible permutations of size m\n",
        "    permutations = list(itertools.permutations(range(m)))\n",
        "\n",
        "    # Initialize a dictionary to count the occurrence of each permutation\n",
        "    permutation_counts = {perm: 0 for perm in permutations}\n",
        "\n",
        "    # Create a list to store the ordinal patterns\n",
        "    ordinal_patterns = []\n",
        "\n",
        "    # Construct ordinal patterns from the time series\n",
        "    for i in range(0, n - (m - 1) * delay):\n",
        "        pattern = [time_series[i + j * delay] for j in range(m)]\n",
        "        ordinal_patterns.append(pattern)\n",
        "\n",
        "    # Count the occurrence of each ordinal pattern\n",
        "    for pattern in ordinal_patterns:\n",
        "        pattern_perm = tuple(sorted(range(m), key=lambda i: pattern[i]))\n",
        "        permutation_counts[pattern_perm] += 1\n",
        "\n",
        "    # Calculate the probabilities of each permutation\n",
        "    probabilities = [count / len(ordinal_patterns) for count in permutation_counts.values()]\n",
        "\n",
        "    # Calculate permutation entropy\n",
        "    perm_entropy = -sum(p * math.log(p, 2) for p in probabilities if p > 0)\n",
        "\n",
        "    return perm_entropy"
      ],
      "metadata": {
        "id": "s7UvvMoTttZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_series = [4, 7, 9, 10, 6, 11, 3]\n",
        "order = 3\n",
        "delay = 1\n",
        "permutation_entropy(time_series, order, delay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPDtRzbpZi6b",
        "outputId": "a5ee9b51-11fa-457a-a10a-80e3a950f66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5219280948873621"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-pFxTHVZxdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EntropyHub"
      ],
      "metadata": {
        "id": "8jolEyDNXzAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install EntropyHub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq6zT6I6XyE4",
        "outputId": "a865fede-5b26-4042-dcb2-e5a20c14c257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting EntropyHub\n",
            "  Downloading EntropyHub-0.2-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from EntropyHub) (1.23.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from EntropyHub) (3.7.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from EntropyHub) (1.10.1)\n",
            "Collecting EMD-signal (from EntropyHub)\n",
            "  Downloading EMD_signal-1.5.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from EntropyHub) (2.31.0)\n",
            "Collecting pathos>=0.2.1 (from EMD-signal->EntropyHub)\n",
            "  Downloading pathos-0.3.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.* (from EMD-signal->EntropyHub)\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->EntropyHub) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->EntropyHub) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->EntropyHub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->EntropyHub) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->EntropyHub) (2023.7.22)\n",
            "Collecting ppft>=1.7.6.7 (from pathos>=0.2.1->EMD-signal->EntropyHub)\n",
            "  Downloading ppft-1.7.6.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.7 (from pathos>=0.2.1->EMD-signal->EntropyHub)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.3 (from pathos>=0.2.1->EMD-signal->EntropyHub)\n",
            "  Downloading pox-0.3.3-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.15 (from pathos>=0.2.1->EMD-signal->EntropyHub)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->EntropyHub) (1.16.0)\n",
            "Installing collected packages: tqdm, ppft, pox, dill, multiprocess, pathos, EMD-signal, EntropyHub\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "Successfully installed EMD-signal-1.5.1 EntropyHub-0.2 dill-0.3.7 multiprocess-0.70.15 pathos-0.3.1 pox-0.3.3 ppft-1.7.6.7 tqdm-4.64.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Approximate Entropy (ApEn):\n",
        "\n",
        "Syntax\n",
        "- Ap, Phi = ApEn(Sig, m = 2, tau = 1, r = 0.2*np.std(Sig), Logx = np.exp(1))\n",
        "\n",
        "Arguments\n",
        "- Sig: Time series signal, a vector of length > 10.\n",
        "- m: Embedding dimension, a positive integer.\n",
        "- tau: Time delay, a positive integer.\n",
        "- r: Distance threshold , a positive scalar.\n",
        "- Logx: Logarithm base in the entropy formula, a positive scalar\n",
        "\n",
        "Outputs\n",
        "- Ap: Approximate entropy estimates, a vector of length m+1.\n",
        "The first value of Ap is the zeroth estimate, and the last value of\n",
        "Ap is the estimate for the specified m.\n",
        "- Phi: The number of matched state vectors for each embedding dimension from 0 to m+1."
      ],
      "metadata": {
        "id": "dLtpZ-f5kUhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import EntropyHub\n",
        "\n",
        "U = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "Ap, Phi = EntropyHub.ApEn(U, 2, 1, 0.2*np.std(U), np.exp(1))"
      ],
      "metadata": {
        "id": "dV7iHbA0aDvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('ApEn: ', Ap)\n",
        "print('Phi: ', Phi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBE5SfN3b0wD",
        "outputId": "a50c7689-e2ce-439c-9e89-495442893f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ApEn:  [ 0.82556609 -0.00094548  0.00094548]\n",
            "Phi:  [ 0.13241891 -0.69314718 -0.6922017  -0.69314718]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_owHPnCdmGSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Entropy (SampEn):\n",
        "\n",
        "Syntax\n",
        "- Samp, A, B = SampEn(Sig, m = 2, tau = 1, r = 0.2*np.std(Sig), Logx = np.exp(1))\n",
        "\n",
        "Arguments\n",
        "- Sig: Time series signal, a vector of length > 10.\n",
        "- m: Embedding dimension, a positive integer.\n",
        "- tau: Time delay, a positive integer.\n",
        "- r: Distance threshold, a positive scalar.\n",
        "- Logx: Logarithm base in the entropy formula, a positive scalar.\n",
        "\n",
        "Outputs\n",
        "- Samp: Sample entropy estimates, a vector of length m+1.\n",
        "The first value of Samp is the zeroth estimate, and\n",
        "the last value of Samp is the estimate for the specified m.\n",
        "- A: The number of matched state vectors for each embedding dimension from 0 to m.\n",
        "- B: The number of matched state vectors for each embedding dimension from 1 to m+1."
      ],
      "metadata": {
        "id": "phuwPeNQn__c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import EntropyHub\n",
        "\n",
        "U = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
        "Samp, A, B = EntropyHub.SampEn(U, 2, 1, 0.2*np.std(U), np.exp(1))"
      ],
      "metadata": {
        "id": "mjqLqffUn-0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('SampEn: ', Samp)\n",
        "print('A: ', A)\n",
        "print('B: ', B)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ESiKOwotLQO",
        "outputId": "21a03ee9-9230-4b8b-ad4f-08d40403f13c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SampEn:  [ 0.73759894 -0.         -0.        ]\n",
            "A:  [132. 121. 110.]\n",
            "B:  [276. 121. 110.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FSudB5aQtW-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Permutation Entropy:\n",
        "\n",
        "Syntax\n",
        "- Perm, Pnorm, cPE = PermEn(Sig, m = 2, tau = 1, Typex = ‘none’, tpx = -1, Logx\n",
        "= 2, Norm = False)\n",
        "\n",
        "Arguments\n",
        "- Sig: Time series signal, a vector of length > 10.\n",
        "It is recommended that length of Sig (N) > 5m!\n",
        "- m: Embedding dimension, an integer > 1.\n",
        "- tau: Time delay, a positive integer.\n",
        "- Typex: Variant of permutation entropy, one of the following strings:\n",
        " - \"finegrain\": Fine-grained permutation entropy\n",
        " - \"modified\": Modified permutation entropy\n",
        " - \"weighted\": Weighted permutation entropy\n",
        " - \"ampaware\": Amplitude-aware permutation entropy\n",
        " - \"edge\": Edge permutation entropy\n",
        " - \"uniquant\": Uniform quantization-based permutation entropy\n",
        "- tpx: Tuning parameter for the permutation entropy specified by the Typex argument.\n",
        " - finegrain: tpx is the α parameter, a positive scalar (default: 1)\n",
        " - ampaware: tpx is the A parameter, a value in range [0 1] (default: 0.5)\n",
        " - edge: tpx is the r sensitivity parameter, a scalar > 0 (default: 1)\n",
        " - uniquant: tpx is the L parameter, an integer > 1 (default: 4).\n",
        "- Logx: Logarithm base in the entropy formula, a positive scalar.\n",
        "- Norm: Normalisation of Perm value, a boolean operator:\n",
        " - false: normalises w.r.t Log(# of permutation symbols [m]) - default\n",
        " - true: normalises w.r.t Log(# of all possible permutations [m!])\n",
        "\n",
        "Outputs\n",
        "- Perm: Permutation entropy estimates for embedding dimensions 1:m.\n",
        "- Pnorm: Normalised Permutation entropy estimates.\n",
        "- cPE: Conditional permutation entropy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uZW0amIhierG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import EntropyHub\n",
        "\n",
        "U = [4, 7, 9, 10, 6, 11, 3, 4, 7, 9, 10, 6, 11, 3]\n",
        "Perm, Pnorm, cPE = EntropyHub.PermEn(U, m = 3, tau = 1, Typex='none', tpx=-1, Logx=2, Norm=False)"
      ],
      "metadata": {
        "id": "bwQsVFmDkDKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('PE: ', Perm)\n",
        "print('PE Normalized: ', Pnorm)\n",
        "print('Conditional PE: ', cPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBjp7w2qga21",
        "outputId": "14750dab-e56e-42d5-e653-bc8fd491de8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PE:  [-0.          0.89049164  1.78415913]\n",
            "PE Normalized:  [       nan 0.89049164 0.89207956]\n",
            "Conditional PE:  [0.89049164 0.89366749]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YFcICkUvlxPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Entropy"
      ],
      "metadata": {
        "id": "TMFMVE-ysEJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Approximate Entropy (XApEn):\n",
        "\n",
        "Syntax\n",
        "- XAp, Phi = XApEn(Sig, m = 2, tau = 1, r = 0.2*np.std(Sig), Logx = np.exp(1))\n",
        "\n",
        "Arguments\n",
        "- Sig: Time series signals, a N x 2 matrix where N > 10.\n",
        "- m: Embedding dimension, a positive integer.\n",
        "- tau: Time delay, a positive integer.\n",
        "- r: Distance threshold, a positive scalar.\n",
        "- Logx: Logarithm base in the entropy formula, a positive scalar.\n",
        "\n",
        "Outputs:\n",
        "- XAp: Cross-approximate entropy estimates, a vector of length m+1.\n",
        "- Phi: The number of matched state vectors for each embedding dimension from 0 to m+1.\n"
      ],
      "metadata": {
        "id": "Klh6ud8ksH4V"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9z9Pch6psGZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cross Sample Entropy (XSampEn):\n",
        "\n",
        "Syntax\n",
        "- XSamp, Phi = XSampEn(Sig, m = 2, tau = 1, r = 0.2*np.std(Sig), Logx = np.exp(1))\n",
        "\n",
        "Arguments\n",
        "- Sig: Time series signals, a N x 2 matrix where N > 10.\n",
        "- m: Embedding dimension, a positive integer.\n",
        "- tau: Time delay, a positive integer.\n",
        "- r: Radius distance threshold, a positive scalar.\n",
        "- Logx: Logarithm base in the entropy formula, a positive scalar.\n",
        "\n",
        "Outputs\n",
        "- XSamp: Cross-sample entropy estimates, a vector of length m+1.\n",
        "- A: The number of matched state vectors for each embedding dimension from 0 to m.\n",
        "- B: The number of matched state vectors for each embedding dimension from 1 to m+1.\n"
      ],
      "metadata": {
        "id": "G3ToKeBUxo-i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MzkuYahsybbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross Permutation Entropy (XPermEn):\n",
        "\n",
        "Syntax\n",
        "- XPerm = XPermEn(Sig, m = 3, tau = 1, Logx = 2)\n",
        "\n",
        "Arguments:\n",
        "- Sig: Time series signals, a N x 2 matrix where N > 10.\n",
        "- m: Embedding dimension, an integer > 2.\n",
        "- tau: Time delay, a positive integer.\n",
        "- Logx: Logarithm base in the entropy formula, a positive scalar.\n",
        "\n",
        "Outputs:\n",
        "- XPerm Cross-permutation entropy estimate.\n"
      ],
      "metadata": {
        "id": "6F3KaTp-ydBp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggqsU3ABycIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}